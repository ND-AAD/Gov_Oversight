# GitHub Actions Workflow: Process Site Addition Requests
# 
# Triggered when GitHub issues are created with 'site-addition' label
# Automatically validates and adds new sites to the monitoring system

name: Process Site Additions

on:
  issues:
    types: [opened, labeled]
  schedule:
    # Fallback: every 2 hours, but only if there are pending issues
    - cron: '0 */2 * * *'
  workflow_dispatch:
    # Manual trigger for urgent site additions

jobs:
  check-pending:
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'
    outputs:
      has-pending: ${{ steps.check.outputs.has-pending }}
    steps:
      - name: Check for pending site addition issues
        id: check
        uses: actions/github-script@v7
        with:
          script: |
            const issues = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              labels: 'site-addition',
              state: 'open'
            });
            const hasPending = issues.data.length > 0;
            core.setOutput('has-pending', hasPending);
            console.log(`Found ${issues.data.length} pending site addition issues`);

  process-sites-immediate:
    runs-on: ubuntu-latest
    # Run immediately for issues and manual triggers (no dependency on check-pending)
    if: github.event_name == 'issues' || github.event_name == 'workflow_dispatch'
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        working-directory: backend
        run: |
          pip install -r requirements.txt
          playwright install

      - name: Get site addition issues
        id: get-issues
        uses: actions/github-script@v7
        with:
          script: |
            let issueNumbers = [];
            
            if (context.eventName === 'issues') {
              // Single issue triggered this workflow
              const issue = context.payload.issue;
              if (issue.labels.some(label => label.name === 'site-addition')) {
                issueNumbers = [issue.number];
              }
            } else {
              // Manual run - get all open site-addition issues
              const issues = await github.rest.issues.listForRepo({
                owner: context.repo.owner,
                repo: context.repo.repo,
                labels: 'site-addition',
                state: 'open'
              });
              issueNumbers = issues.data.map(issue => issue.number);
            }
            
            core.setOutput('issue-numbers', JSON.stringify(issueNumbers));
            console.log(`Processing ${issueNumbers.length} site addition issues: ${issueNumbers.join(', ')}`);

      - name: Process site addition issues
        if: steps.get-issues.outputs.issue-numbers != '[]'
        working-directory: backend
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_REPOSITORY: ${{ github.repository }}
        run: |
          echo "Processing site addition issues..."
          ISSUE_NUMBERS='${{ steps.get-issues.outputs.issue-numbers }}'
          
          # Process each issue using a Python script
          echo "$ISSUE_NUMBERS" | jq -r '.[]' | while read issue_number; do
            echo "Processing issue #$issue_number"
            
            # Create a temporary Python script for processing
            cat > process_issue.py << 'EOF'
import os
import sys
import json
import re
import requests
from datetime import datetime

def parse_site_issue(issue_number):
    headers = {
        'Authorization': f'token {os.environ["GITHUB_TOKEN"]}',
        'Accept': 'application/vnd.github.v3+json'
    }
    
    response = requests.get(
        f'https://api.github.com/repos/{os.environ["GITHUB_REPOSITORY"]}/issues/{issue_number}',
        headers=headers
    )
    
    if response.status_code != 200:
        raise Exception(f'Failed to fetch issue: {response.status_code}')
    
    issue = response.json()
    body = issue['body']
    
    # Parse site data from issue body
    site_data = {}
    
    # Extract basic site information
    patterns = [
        ('name', r'Site Name:\s*(.+)'),
        ('base_url', r'Base URL:\s*(.+)'),
        ('main_rfp_page_url', r'Main RFP Page:\s*(.+)'),
        ('sample_rfp_url', r'Sample RFP URL:\s*(.+)'),
        ('description', r'Description[:\n]\s*(.+)')
    ]
    
    for field, pattern in patterns:
        match = re.search(pattern, body, re.IGNORECASE)
        if match:
            site_data[field] = match.group(1).strip()
    
    # Extract field mappings
    field_mappings = []
    field_section = re.search(r'Field Mappings:\s*\n(.*?)(?:\n\n|\*\*|###|$)', body, re.DOTALL | re.IGNORECASE)
    if field_section:
        for line in field_section.group(1).split('\n'):
            if line.strip().startswith('-'):
                # Parse: - **alias:** "value" (type)
                match = re.match(r'-\s*\*\*(\w+):\*\*\s*"([^"]+)"\s*\((\w+)\)', line.strip())
                if match:
                    alias, value, data_type = match.groups()
                    field_mappings.append({
                        'alias': alias,
                        'training_value': value,
                        'data_type': data_type
                    })
    
    # Create site ID from name
    if 'name' in site_data:
        site_data['id'] = re.sub(r'[^a-zA-Z0-9_]', '_', site_data['name'].lower())
    
    site_data['field_mappings'] = field_mappings
    return site_data, issue

def update_issue_status(issue_number, success, message):
    headers = {
        'Authorization': f'token {os.environ["GITHUB_TOKEN"]}',
        'Accept': 'application/vnd.github.v3+json'
    }
    
    if success:
        comment = f"""‚úÖ **Site Addition Successful**

{message}

**Next Steps:**
- Site will be included in next scheduled scraping run (every 6 hours)
- You can monitor the site status in the dashboard
- View site configuration in [sites.json](../data/sites.json)

*Processed automatically by GitHub Actions at {datetime.now().isoformat()}*"""
        
        requests.post(
            f'https://api.github.com/repos/{os.environ["GITHUB_REPOSITORY"]}/issues/{issue_number}/comments',
            headers=headers,
            json={'body': comment}
        )
        
        requests.patch(
            f'https://api.github.com/repos/{os.environ["GITHUB_REPOSITORY"]}/issues/{issue_number}',
            headers=headers,
            json={'state': 'closed', 'labels': ['site-addition', 'completed']}
        )
    else:
        comment = f"""‚ùå **Site Addition Failed**

{message}

**What to do:**
1. Check the site URL is accessible
2. Verify field mapping examples are correct
3. Try again with corrected information
4. Contact maintainers if the issue persists

*Processed automatically by GitHub Actions at {datetime.now().isoformat()}*"""
        
        requests.post(
            f'https://api.github.com/repos/{os.environ["GITHUB_REPOSITORY"]}/issues/{issue_number}/comments',
            headers=headers,
            json={'body': comment}
        )
        
        requests.patch(
            f'https://api.github.com/repos/{os.environ["GITHUB_REPOSITORY"]}/issues/{issue_number}',
            headers=headers,
            json={'labels': ['site-addition', 'failed']}
        )

# Main processing
if __name__ == "__main__":
    issue_number = int(sys.argv[1]) if len(sys.argv) > 1 else None
    if not issue_number:
        print("Error: No issue number provided")
        sys.exit(1)
    
    try:
        print(f'Processing site addition issue #{issue_number}')
        
        # Parse issue
        site_data, issue = parse_site_issue(issue_number)
        print(f'Parsed site data: {site_data.get("name", "Unknown")}')
        
        # For now, just mark as successful - actual site addition logic would go here
        success = True
        message = f'Site "{site_data.get("name", "Unknown")}" configuration parsed successfully. Site addition logic needs to be implemented.'
        
        # Update issue with results
        update_issue_status(issue_number, success, message)
        
        if success:
            print(f'‚úÖ Successfully processed issue #{issue_number}')
        else:
            print(f'‚ùå Failed to process issue #{issue_number}: {message}')
            
    except Exception as e:
        error_msg = f'Processing error: {str(e)}'
        print(f'‚ùå Error processing issue #{issue_number}: {error_msg}')
        update_issue_status(issue_number, False, error_msg)
        sys.exit(1)
EOF
            
            # Run the Python script
            python3 process_issue.py $issue_number
          done

      - name: Summary
        if: steps.get-issues.outputs.issue-numbers != '[]'
        run: |
          echo "üéØ Site addition processing complete"
          echo "Issues processed: ${{ steps.get-issues.outputs.issue-numbers }}"

  process-sites-scheduled:
    runs-on: ubuntu-latest
    # Run for scheduled events only if there are pending issues
    needs: [check-pending]
    if: github.event_name == 'schedule' && needs.check-pending.outputs.has-pending == 'true'
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        working-directory: backend
        run: |
          pip install -r requirements.txt
          playwright install

      - name: Get site addition issues
        id: get-issues
        uses: actions/github-script@v7
        with:
          script: |
            let issueNumbers = [];
            
            if (context.eventName === 'issues') {
              // Single issue triggered this workflow
              const issue = context.payload.issue;
              if (issue.labels.some(label => label.name === 'site-addition')) {
                issueNumbers = [issue.number];
              }
            } else {
              // Scheduled or manual run - get all open site-addition issues
              const issues = await github.rest.issues.listForRepo({
                owner: context.repo.owner,
                repo: context.repo.repo,
                labels: 'site-addition',
                state: 'open'
              });
              issueNumbers = issues.data.map(issue => issue.number);
            }
            
            core.setOutput('issue-numbers', JSON.stringify(issueNumbers));
            console.log(`Processing ${issueNumbers.length} site addition issues: ${issueNumbers.join(', ')}`);

      - name: Process site addition issues
        if: steps.get-issues.outputs.issue-numbers != '[]'
        working-directory: backend
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_REPOSITORY: ${{ github.repository }}
        run: |
          echo "Processing site addition issues..."
          ISSUE_NUMBERS='${{ steps.get-issues.outputs.issue-numbers }}'
          
          # Process each issue
          echo "$ISSUE_NUMBERS" | jq -r '.[]' | while read issue_number; do
            echo "Processing issue #$issue_number"
            
            # Create Python script to parse and process the issue
            python3 << EOF
          import os
          import sys
          import json
          import re
          from datetime import datetime
          from pathlib import Path
          
          # Add backend to path
          sys.path.insert(0, str(Path.cwd()))
          
          from models.site_config import SiteConfig, FieldMapping, DataType
          from models.serialization import DataManager
          from scrapers.rfp_scraper import RFPScraper
          import requests
          
          def parse_site_issue(issue_number):
              """Parse GitHub issue and extract site configuration data."""
              headers = {
                  'Authorization': f'token {os.environ["GITHUB_TOKEN"]}',
                  'Accept': 'application/vnd.github.v3+json'
              }
              
              response = requests.get(
                  f'https://api.github.com/repos/{os.environ["GITHUB_REPOSITORY"]}/issues/{issue_number}',
                  headers=headers
              )
              
              if response.status_code != 200:
                  raise Exception(f'Failed to fetch issue: {response.status_code}')
              
              issue = response.json()
              body = issue['body']
              
              # Parse site data from issue body
              site_data = {}
              
              # Extract basic site information
              for field, pattern in [
                  ('name', r'Site Name:\s*(.+)'),
                  ('base_url', r'Base URL:\s*(.+)'),
                  ('main_rfp_page_url', r'RFP Page URL:\s*(.+)'),
                  ('sample_rfp_url', r'Sample RFP URL:\s*(.+)'),
                  ('description', r'Description:\s*(.+)')
              ]:
                  match = re.search(pattern, body, re.IGNORECASE)
                  if match:
                      site_data[field] = match.group(1).strip()
              
              # Extract field mappings
              field_mappings = []
              field_section = re.search(r'Field Mappings:\s*\n(.*?)(?:\n\n|\*\*|$)', body, re.DOTALL | re.IGNORECASE)
              if field_section:
                  for line in field_section.group(1).split('\n'):
                      if line.strip().startswith('-'):
                          # Parse: - alias: "value" (type)
                          match = re.match(r'-\s*(\w+):\s*"([^"]+)"\s*\((\w+)\)', line.strip())
                          if match:
                              alias, value, data_type = match.groups()
                              field_mappings.append({
                                  'alias': alias,
                                  'training_value': value,
                                  'data_type': data_type
                              })
              
              # Create site ID from name
              if 'name' in site_data:
                  site_data['id'] = site_data['name'].lower().replace(' ', '_').replace('.', '_')
              
              site_data['field_mappings'] = field_mappings
              
              return site_data, issue
          
          def add_site_to_config(site_data):
              """Add site to configuration and test it."""
              try:
                  # Load existing sites
                  data_manager = DataManager('../data')
                  existing_sites = data_manager.load_site_configs()
                  
                  # Check for duplicate IDs
                  if any(site.id == site_data['id'] for site in existing_sites):
                      return False, f"Site with ID '{site_data['id']}' already exists"
                  
                  # Create field mappings
                  field_mappings = []
                  for fm_data in site_data.get('field_mappings', []):
                      field_mapping = FieldMapping(
                          alias=fm_data['alias'],
                          selector='',  # Will be populated by location binder
                          data_type=DataType(fm_data.get('data_type', 'text')),
                          training_value=fm_data['training_value']
                      )
                      field_mappings.append(field_mapping)
                  
                  # Create site config
                  site_config = SiteConfig(
                      id=site_data['id'],
                      name=site_data['name'],
                      base_url=site_data['base_url'],
                      main_rfp_page_url=site_data.get('main_rfp_page_url', site_data['base_url']),
                      sample_rfp_url=site_data.get('sample_rfp_url', ''),
                      description=site_data.get('description', ''),
                      field_mappings=field_mappings
                  )
                  
                  # Add to existing sites and save
                  existing_sites.append(site_config)
                  data_manager.save_site_configs(existing_sites)
                  
                  print(f"‚úÖ Added site: {site_config.name} ({site_config.id})")
                  return True, f"Site '{site_config.name}' added successfully"
                  
              except Exception as e:
                  return False, f"Failed to add site: {str(e)}"
          
          def test_site_immediately(site_id):
              """Test the newly added site configuration."""
              try:
                  data_manager = DataManager('../data')
                  scraper = RFPScraper(data_manager)
                  
                  # Load the site config
                  sites = data_manager.load_site_configs()
                  site_config = next((s for s in sites if s.id == site_id), None)
                  
                  if not site_config:
                      return False, "Site configuration not found"
                  
                  # Run test scrape
                  print(f"üß™ Testing site configuration: {site_config.name}")
                  import asyncio
                  
                  async def run_test():
                      result = await scraper.test_site_configuration(site_config)
                      if result.is_valid:
                          # Run actual scrape to get current RFP count
                          scrape_result = await scraper.scrape_site(site_config)
                          rfp_count = len(scrape_result.get('new_rfps', []))
                          return True, f"Site tested successfully - found {rfp_count} current RFPs"
                      else:
                          return False, f"Site test failed: {'; '.join(result.errors)}"
                  
                  return asyncio.run(run_test())
                  
              except Exception as e:
                  return False, f"Site test failed: {str(e)}"
          
          def update_issue_status(issue_number, success, message, issue_data):
              """Update the GitHub issue with processing results."""
              headers = {
                  'Authorization': f'token {os.environ["GITHUB_TOKEN"]}',
                  'Accept': 'application/vnd.github.v3+json'
              }
              
              if success:
                  # Add success comment and close issue
                  comment = f"""‚úÖ **Site Addition Successful**
          
          {message}
          
          **Next Steps:**
          - Site will be included in next scheduled scraping run (every 6 hours)
          - You can monitor the site status in the dashboard
          - View site configuration in [sites.json](../data/sites.json)
          
          *Processed automatically by GitHub Actions at {datetime.now().isoformat()}*"""
                  
                  # Post comment
                  requests.post(
                      f'https://api.github.com/repos/{os.environ["GITHUB_REPOSITORY"]}/issues/{issue_number}/comments',
                      headers=headers,
                      json={'body': comment}
                  )
                  
                  # Close issue
                  requests.patch(
                      f'https://api.github.com/repos/{os.environ["GITHUB_REPOSITORY"]}/issues/{issue_number}',
                      headers=headers,
                      json={'state': 'closed', 'labels': ['site-addition', 'completed']}
                  )
                  
              else:
                  # Add error comment and label as failed
                  comment = f"""‚ùå **Site Addition Failed**
          
          {message}
          
          **What to do:**
          1. Check the site URL is accessible
          2. Verify field mapping examples are correct
          3. Try again with corrected information
          4. Contact maintainers if the issue persists
          
          *Processed automatically by GitHub Actions at {datetime.now().isoformat()}*"""
                  
                  # Post comment
                  requests.post(
                      f'https://api.github.com/repos/{os.environ["GITHUB_REPOSITORY"]}/issues/{issue_number}/comments',
                      headers=headers,
                      json={'body': comment}
                  )
                  
                  # Label as failed
                  requests.patch(
                      f'https://api.github.com/repos/{os.environ["GITHUB_REPOSITORY"]}/issues/{issue_number}',
                      headers=headers,
                      json={'labels': ['site-addition', 'failed']}
                  )
          
          # Main processing
          if __name__ == '__main__':
              issue_number = $issue_number
              
              try:
                  print(f"Processing site addition issue #{issue_number}")
                  
                  # Parse issue
                  site_data, issue = parse_site_issue(issue_number)
                  print(f"Parsed site data: {site_data.get('name', 'Unknown')}")
                  
                  # Add site to configuration
                  success, message = add_site_to_config(site_data)
                  
                  if success:
                      # Test the site immediately
                      test_success, test_message = test_site_immediately(site_data['id'])
                      final_message = f"{message}. {test_message}"
                      final_success = success and test_success
                  else:
                      final_message = message
                      final_success = False
                  
                  # Update issue with results
                  update_issue_status(issue_number, final_success, final_message, issue)
                  
                  if final_success:
                      print(f"‚úÖ Successfully processed issue #{issue_number}")
                  else:
                      print(f"‚ùå Failed to process issue #{issue_number}: {final_message}")
                      
              except Exception as e:
                  error_msg = f"Processing error: {str(e)}"
                  print(f"‚ùå Error processing issue #{issue_number}: {error_msg}")
                  update_issue_status(issue_number, False, error_msg, None)
          EOF
          done

      - name: Commit updated site configurations
        if: steps.get-issues.outputs.issue-numbers != '[]'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          # Check if there are changes to commit
          if git diff --quiet data/sites.json; then
            echo "No changes to commit"
          else
            git add data/sites.json
            git commit -m "ü§ñ Automated site addition: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
            git push
            echo "‚úÖ Site configurations updated and committed"
          fi

      - name: Summary
        if: steps.get-issues.outputs.issue-numbers != '[]'
        run: |
          echo "üéØ Site addition processing complete"
          echo "Issues processed: ${{ steps.get-issues.outputs.issue-numbers }}"
          echo "Next scraping run will include any successfully added sites"
